{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Open and run analysis on multiple polygons <img align=\"right\" src=\"../Supplementary_data/dea_logo.jpg\">\n",
    "\n",
    "* **Compatability:** Notebook currently compatible with both the `NCI` and `DEA Sandbox` environments\n",
    "* **Products used:** \n",
    "[s2a_ard_granule](https://explorer.sandbox.dea.ga.gov.au/s2a_ard_granule), \n",
    "[s2b_ard_granule](https://explorer.sandbox.dea.ga.gov.au/s2b_ard_granule)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background\n",
    "Many users need to run analyses on their own areas of interest. \n",
    "A common use case involves running the same analysis across multiple polygons in a vector file (e.g. ESRI Shapefile or GeoJSON). \n",
    "This notebook will demonstrate how to use a vector file and the Open Data Cube to extract satellite data from Digital Earth Australia corresponding to individual polygon geometries."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description\n",
    "If we have a vector file containing multiple polygons, we can use the python package [geopandas](https://geopandas.org/) to open it as a `GeoDataFrame`. \n",
    "We can then iterate through each geometry and extract satellite data corresponding with the extent of each geometry. \n",
    "Further anlaysis can then be conducted on each resulting `xarray.Dataset`.\n",
    "\n",
    "We can retrieve data for each polygon, perform an analysis like calculating NDVI and plot the data.\n",
    "\n",
    "1. First we open the polygon using `geopandas`\n",
    "2. Iterate through  a geodatframe, extracting satellite data from DEA's ODC\n",
    "3. Calculate NDVI as an example analysis on one of the extracted satellite timeseries.\n",
    "4. Plot NDVI for the polygon extent\n",
    "\n",
    "***\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Getting started\n",
    "To run this analysis, run all the cells in the notebook, starting with the \"Load packages\" cell. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load packages\n",
    "Please note the use of `datacube.utils` package `geometry`: \n",
    "this is important for saving the coordinate reference system of the incoming shapefile in a format that the Digital Earth Australia query can understand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import datacube\n",
    "import rasterio.crs\n",
    "import geopandas as gpd\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from datacube.utils import geometry\n",
    "\n",
    "import sys\n",
    "sys.path.append('../Scripts')\n",
    "from dea_datahandling import load_ard\n",
    "from dea_bandindices import calculate_indices\n",
    "from dea_plotting import rgb, map_shapefile\n",
    "from dea_temporaltools import time_buffer\n",
    "from dea_spatialtools import xr_rasterize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Connect to the datacube\n",
    "Connect to the datacube database to enable loading Digital Earth Australia data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Datacube<index=Index<db=PostgresDb<engine=Engine(postgresql://sandbox_reader:***@db-aurora-dea-sandbox-eks.cluster-ro-cos5zfpkso9m.ap-southeast-2.rds.amazonaws.com:5432/sandbox)>>>"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Temporary solution to account for Sentinel2 data being in a different\n",
    "# database on the NCI\n",
    "dc = datacube.Datacube(app=\"Sentinel_2\")\n",
    "dc\n",
    "#try:\n",
    "#    dc = datacube.Datacube(app='Analyse_multiple_polygons', env='c3-samples')\n",
    "#except:\n",
    "#    dc = datacube.Datacube(app='Analyse_multiple_polygons')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis parameters\n",
    "\n",
    "* `time_of_interest` : Enter a time, in units YYYY-MM-DD, around which to load satellite data e.g. `'2019-01-01'`\n",
    "* `time_buff` : A buffer of a given duration (e.g. days) around the time_of_interest parameter, e.g. `'30 days'`\n",
    "* `vector_file` : A path to a vector file (ESRI Shapefile or GeoJSON)\n",
    "* `attribute_col` : A column in the vector file used to label the output `xarray` datasets containing satellite images. Each row of this column should have a unique identifier\n",
    "* `products` : A list of product names to load from the datacube e.g. `['ga_ls7e_ard_3', 'ga_ls8c_ard_3']`\n",
    "* `measurements` : A list of band names to load from the satellite product e.g. `['nbart_red', 'nbart_green']`\n",
    "* `resolution` : The spatial resolution of the loaded satellite data e.g. for Landsat, this is `(-30, 30)`\n",
    "* `output_crs` : The coordinate reference system/map projection to load data into, e.g. `'EPSG:3577'` to load data in the Albers Equal Area projection\n",
    "* `align` : How to align the x, y coordinates respect to each pixel. Landsat Collection 3 should be centre aligned `align = (15, 15)` if data is loaded in its native UTM zone projection, e.g. `'EPSG:32756'` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "time_range = ('2015-06', '2020-11')\n",
    "\n",
    "vector_file = '../Fitzgerald/FitzNP_PossVegPlots_2020_31to45.shp'\n",
    "attribute_col = 'SiteName'\n",
    "\n",
    "products = ['s2a_ard_granule', 's2b_ard_granule']\n",
    "measurements = ['nbart_blue', 'nbart_green', 'nbart_red', 'nbart_red_edge_1', 'nbart_red_edge_2', 'nbart_red_edge_3', 'nbart_nir_1','nbart_nir_2','nbart_swir_2','nbart_swir_3']\n",
    "resolution = (-10, 10)\n",
    "output_crs = 'EPSG:3577'\n",
    "align = (0, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Look at the structure of the vector file\n",
    "Import the file and take a look at how the file is structured so we understand what we are iterating through. \n",
    "There are two polygons in the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf = gpd.read_file(vector_file)\n",
    "#gdf.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "gdfp = gdf\n",
    "gdfp['geometry'] = gdfp.geometry.buffer(2000)\n",
    "#gdfp.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then plot the `geopandas.GeoDataFrame` using the function `map_shapefile` to make sure it covers the area of interest we are concerned with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c601d9067bcc4d3683d9ea81c54183e6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Label(value='')"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "eb7e26c555f340929fe53e13ece7c393",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Map(center=[-33.92765952297655, 120.00527843202829], controls=(ZoomControl(options=['position', 'zoom_in_text'â€¦"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "map_shapefile(gdfp, attribute=attribute_col)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a datacube query object\n",
    "We then create a dictionary that will contain the parameters that will be used to load data from the DEA data cube:\n",
    "\n",
    "> **Note:** We do not include the usual `x` and `y` spatial query parameters here, as these will be taken directly from each of our vector polygon objects."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>SiteName</th>\n",
       "      <th>AerialPhot</th>\n",
       "      <th>Comment</th>\n",
       "      <th>geometry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>EMB_031_050</td>\n",
       "      <td>Hopetoun_to_Esperance_Coastline_May_2016_Mosai...</td>\n",
       "      <td>None</td>\n",
       "      <td>POLYGON ((-1103296.467 -3754422.294, -1103299....</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id     SiteName                                         AerialPhot Comment  \\\n",
       "0   0  EMB_031_050  Hopetoun_to_Esperance_Coastline_May_2016_Mosai...    None   \n",
       "\n",
       "                                            geometry  \n",
       "0  POLYGON ((-1103296.467 -3754422.294, -1103299....  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "query = {'time': time_range,\n",
    "         'measurements': measurements,\n",
    "         'resolution': resolution,\n",
    "         'output_crs': output_crs,\n",
    "         'align': align,\n",
    "         }\n",
    "\n",
    "query\n",
    "gdf.iloc[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 2/5\n",
      "Finding datasets\n",
      "    s2a_ard_granule\n",
      "    s2b_ard_granule\n",
      "Counting good quality pixels for each time step\n",
      "Filtering to 84 out of 229 time steps with at least 80.0% good quality pixels\n",
      "Applying pixel quality/cloud mask\n",
      "Loading 84 time steps\n",
      "Feature: 2/5\n",
      "Finding datasets\n",
      "    s2a_ard_granule\n",
      "    s2b_ard_granule\n",
      "Counting good quality pixels for each time step\n",
      "Filtering to 85 out of 229 time steps with at least 80.0% good quality pixels\n",
      "Applying pixel quality/cloud mask\n",
      "Loading 85 time steps\n",
      "Feature: 2/5\n",
      "Finding datasets\n",
      "    s2a_ard_granule\n",
      "    s2b_ard_granule\n",
      "Counting good quality pixels for each time step\n",
      "Filtering to 85 out of 229 time steps with at least 80.0% good quality pixels\n",
      "Applying pixel quality/cloud mask\n",
      "Loading 85 time steps\n",
      "Feature: 2/5\n",
      "Finding datasets\n",
      "    s2a_ard_granule\n",
      "    s2b_ard_granule\n",
      "Counting good quality pixels for each time step\n",
      "Filtering to 85 out of 229 time steps with at least 80.0% good quality pixels\n",
      "Applying pixel quality/cloud mask\n",
      "Loading 85 time steps\n",
      "Feature: 2/5\n",
      "Finding datasets\n",
      "    s2a_ard_granule\n",
      "    s2b_ard_granule\n",
      "Counting good quality pixels for each time step\n",
      "Filtering to 85 out of 229 time steps with at least 80.0% good quality pixels\n",
      "Applying pixel quality/cloud mask\n",
      "Loading 85 time steps\n",
      "Feature: 2/5\n",
      "Finding datasets\n",
      "    s2a_ard_granule\n",
      "    s2b_ard_granule\n",
      "Counting good quality pixels for each time step\n",
      "Filtering to 87 out of 229 time steps with at least 80.0% good quality pixels\n",
      "Applying pixel quality/cloud mask\n",
      "Loading 87 time steps\n",
      "Feature: 2/5\n",
      "Finding datasets\n",
      "    s2a_ard_granule\n",
      "    s2b_ard_granule\n",
      "Counting good quality pixels for each time step\n",
      "Filtering to 86 out of 229 time steps with at least 80.0% good quality pixels\n",
      "Applying pixel quality/cloud mask\n",
      "Loading 86 time steps\n",
      "Feature: 2/5\n",
      "Finding datasets\n",
      "    s2a_ard_granule\n",
      "    s2b_ard_granule\n",
      "Counting good quality pixels for each time step\n",
      "Filtering to 87 out of 229 time steps with at least 80.0% good quality pixels\n",
      "Applying pixel quality/cloud mask\n",
      "Loading 87 time steps\n",
      "Feature: 2/5\n",
      "Finding datasets\n",
      "    s2a_ard_granule\n",
      "    s2b_ard_granule\n",
      "Counting good quality pixels for each time step\n",
      "Filtering to 88 out of 229 time steps with at least 80.0% good quality pixels\n",
      "Applying pixel quality/cloud mask\n",
      "Loading 88 time steps\n",
      "Feature: 2/5\n",
      "Finding datasets\n",
      "    s2a_ard_granule\n",
      "    s2b_ard_granule\n",
      "Counting good quality pixels for each time step\n",
      "Filtering to 87 out of 229 time steps with at least 80.0% good quality pixels\n",
      "Applying pixel quality/cloud mask\n",
      "Loading 87 time steps\n",
      "Feature: 2/5\n",
      "Finding datasets\n",
      "    s2a_ard_granule\n",
      "    s2b_ard_granule\n",
      "Counting good quality pixels for each time step\n",
      "Filtering to 86 out of 229 time steps with at least 80.0% good quality pixels\n",
      "Applying pixel quality/cloud mask\n",
      "Loading 86 time steps\n",
      "Feature: 2/5\n",
      "Finding datasets\n",
      "    s2a_ard_granule\n",
      "    s2b_ard_granule\n",
      "Counting good quality pixels for each time step\n",
      "Filtering to 86 out of 229 time steps with at least 80.0% good quality pixels\n",
      "Applying pixel quality/cloud mask\n",
      "Loading 86 time steps\n",
      "Feature: 2/5\n",
      "Finding datasets\n",
      "    s2a_ard_granule\n",
      "    s2b_ard_granule\n",
      "Counting good quality pixels for each time step\n",
      "Filtering to 85 out of 229 time steps with at least 80.0% good quality pixels\n",
      "Applying pixel quality/cloud mask\n",
      "Loading 85 time steps\n",
      "Feature: 2/5\n",
      "Finding datasets\n",
      "    s2a_ard_granule\n",
      "    s2b_ard_granule\n",
      "Counting good quality pixels for each time step\n",
      "Filtering to 82 out of 229 time steps with at least 80.0% good quality pixels\n",
      "Applying pixel quality/cloud mask\n",
      "Loading 82 time steps\n",
      "Feature: 2/5\n",
      "Finding datasets\n",
      "    s2a_ard_granule\n",
      "    s2b_ard_granule\n",
      "Counting good quality pixels for each time step\n",
      "Filtering to 81 out of 229 time steps with at least 80.0% good quality pixels\n",
      "Applying pixel quality/cloud mask\n",
      "Loading 81 time steps\n"
     ]
    }
   ],
   "source": [
    "# Dictionary to save results \n",
    "results = {}\n",
    "\n",
    "# A progress indicator\n",
    "i = 1\n",
    "\n",
    "\n",
    "# Loop through polygons in geodataframe and extract satellite data\n",
    "for index, row in gdf.iloc[:].iterrows():\n",
    "    \n",
    "    print(f'Feature: {i + 1}/5') #{len(gdf)} \n",
    "    \n",
    "    # Get the geometry\n",
    "    try:\n",
    "        # If on the DEA Sandbox\n",
    "        geom = geometry.Geometry(row.geometry.__geo_interface__,\n",
    "                                 geometry.CRS(gdf.crs))\n",
    "    except:\n",
    "        # If on the NCI\n",
    "        crs_wkt = rasterio.crs.CRS(gdf.crs).to_wkt()\n",
    "        geom = geometry.Geometry(row.geometry.__geo_interface__,\n",
    "                                 geometry.CRS(crs_wkt))\n",
    "    \n",
    "    # Update dc query with geometry      \n",
    "    query.update({'geopolygon': geom}) \n",
    "    \n",
    "    # Load landsat\n",
    "    ds = load_ard(dc=dc, \n",
    "                  products=products,\n",
    "                  min_gooddata=0.80,  # only take uncloudy scenes\n",
    "#                  ls7_slc_off = True,                  \n",
    "#                  group_by='solar_day',\n",
    "                  **query\n",
    "                 )\n",
    "\n",
    "    # Generate a polygon mask to keep only data within the polygon\n",
    "    mask = xr_rasterize(gdf.iloc[[index]], ds) #for data vals\n",
    "    maskp = xr_rasterize(gdfp.iloc[[index]], ds) #for plot\n",
    "    \n",
    "    # Mask dataset to set pixels outside the polygon to `NaN`\n",
    "    ds = ds.where(mask)\n",
    "    dsp = ds.where(maskp) #for plot\n",
    "    \n",
    "    # Append results to a dictionary using the attribute\n",
    "    # column as an key\n",
    "    results.update({str(row[attribute_col]) : ds})\n",
    "    \n",
    "    for key in results.keys():\n",
    "        wname = key\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature: 1/1\n",
      "Finding datasets\n",
      "    s2a_ard_granule\n",
      "    s2b_ard_granule\n",
      "Counting good quality pixels for each time step\n",
      "Filtering to 78 out of 229 time steps with at least 80.0% good quality pixels\n",
      "Applying pixel quality/cloud mask\n",
      "Loading 78 time steps\n"
     ]
    }
   ],
   "source": [
    "  \n",
    "    ## Create images of each plot for QA purposes\n",
    "    for time, i in dsp.groupby('time'):\n",
    "        # To plot the RGB array, first we need to load it\n",
    "        # as a 3D numpy array with bands as the final axis\n",
    "        rgb_array = np.transpose(i[[\"nbart_swir_2\", \"nbart_nir_1\", \"nbart_green\"]]\n",
    "                                 .to_array()\n",
    "                                  .values, \n",
    "                                 axes=[1, 2, 0])\n",
    "        # Divide by 3000 to keep values between 0 and 1,\n",
    "        # and create a reasonably good colour stretch\n",
    "        rgb_array = (rgb_array / 3000).clip(0, 1)\n",
    "        \n",
    "        fig, ax = plt.subplots(figsize=(30, 30))\n",
    "        \n",
    "        ax.imshow(rgb_array, \n",
    "                  extent=(i.x.min().item(), \n",
    "                          i.x.max().item(), \n",
    "                          i.y.min().item(), \n",
    "                          i.y.max().item()))\n",
    "        # Export RGB image to file\n",
    "        rgb_png = f'S2_{wname}_{str(time)[0:10]}_{str(vector_file)[23:28]}_542.png'\n",
    "        fig.savefig(rgb_png, bbox_inches='tight')\n",
    "        plt.close(fig) \n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading satellite data\n",
    "\n",
    "Here we will iterate through each row of the `geopandas.GeoDataFrame` and load satellite data.  The results will be appended to a dictionary object which we can later index to analyse each dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Further analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our `results` dictionary will contain `xarray` objects labelled by the unique `attribute column` values we specified in the `Analysis parameters` section:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define column names\n",
    "colNames = ('nbart_blue', 'nbart_green', 'nbart_red', 'nbart_red_edge_1', 'nbart_red_edge_2', 'nbart_red_edge_3', 'nbart_nir_1','nbart_nir_2','nbart_swir_2','nbart_swir_3')\n",
    "\n",
    "# Empty list\n",
    "dfs = []\n",
    "\n",
    "# Create a dataframe for each polygon\n",
    "for key in results.keys():\n",
    "    tempDF = pd.DataFrame(columns = colNames)\n",
    "    tempDF['date'] = results[key].time.values\n",
    "    tempDF['site'] = key\n",
    "    tempDF['blue'] = results[key].nbart_blue.mean(dim=['x', 'y'], skipna = True)\n",
    "    tempDF['green'] = results[key].nbart_green.mean(dim=['x', 'y'], skipna = True)\n",
    "    tempDF['red'] = results[key].nbart_red.mean(dim=['x', 'y'], skipna = True)\n",
    "    tempDF['red_edge1'] = results[key].nbart_red_edge_1.mean(dim=['x', 'y'], skipna = True)\n",
    "    tempDF['red_edge2'] = results[key].nbart_red_edge_2.mean(dim=['x', 'y'], skipna = True)\n",
    "    tempDF['red_edge3'] = results[key].nbart_red_edge_3.mean(dim=['x', 'y'], skipna = True)\n",
    "    tempDF['nir1'] = results[key].nbart_nir_1.mean(dim=['x', 'y'], skipna = True)\n",
    "    tempDF['nir2'] = results[key].nbart_nir_2.mean(dim=['x', 'y'], skipna = True)\n",
    "    tempDF['swir2'] = results[key].nbart_swir_2.mean(dim=['x', 'y'], skipna = True)\n",
    "    tempDF['swir3'] = results[key].nbart_swir_3.mean(dim=['x', 'y'], skipna = True)\n",
    "    \n",
    "    #print(tempDF)\n",
    "    #print('\\n')\n",
    "\n",
    "    # Try to append temporary DF to master DF\n",
    "    dfs.append(tempDF)\n",
    "\n",
    "masterDF = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     nbart_blue nbart_green nbart_red nbart_red_edge_1 nbart_red_edge_2  \\\n",
      "0           NaN         NaN       NaN              NaN              NaN   \n",
      "1           NaN         NaN       NaN              NaN              NaN   \n",
      "2           NaN         NaN       NaN              NaN              NaN   \n",
      "3           NaN         NaN       NaN              NaN              NaN   \n",
      "4           NaN         NaN       NaN              NaN              NaN   \n",
      "...         ...         ...       ...              ...              ...   \n",
      "1274        NaN         NaN       NaN              NaN              NaN   \n",
      "1275        NaN         NaN       NaN              NaN              NaN   \n",
      "1276        NaN         NaN       NaN              NaN              NaN   \n",
      "1277        NaN         NaN       NaN              NaN              NaN   \n",
      "1278        NaN         NaN       NaN              NaN              NaN   \n",
      "\n",
      "     nbart_red_edge_3 nbart_nir_1 nbart_nir_2 nbart_swir_2 nbart_swir_3  ...  \\\n",
      "0                 NaN         NaN         NaN          NaN          NaN  ...   \n",
      "1                 NaN         NaN         NaN          NaN          NaN  ...   \n",
      "2                 NaN         NaN         NaN          NaN          NaN  ...   \n",
      "3                 NaN         NaN         NaN          NaN          NaN  ...   \n",
      "4                 NaN         NaN         NaN          NaN          NaN  ...   \n",
      "...               ...         ...         ...          ...          ...  ...   \n",
      "1274              NaN         NaN         NaN          NaN          NaN  ...   \n",
      "1275              NaN         NaN         NaN          NaN          NaN  ...   \n",
      "1276              NaN         NaN         NaN          NaN          NaN  ...   \n",
      "1277              NaN         NaN         NaN          NaN          NaN  ...   \n",
      "1278              NaN         NaN         NaN          NaN          NaN  ...   \n",
      "\n",
      "            blue       green         red   red_edge1    red_edge2  \\\n",
      "0     485.862183  608.855103  638.493713  902.733093  1326.578491   \n",
      "1     473.963928  592.885986  520.461426  754.306824  1336.339722   \n",
      "2     356.639130  454.596893  413.274109  641.886780  1258.748779   \n",
      "3     270.641510  404.021057  379.341370  645.234436  1353.003296   \n",
      "4     505.018127  595.364746  566.840088  788.421997  1249.571411   \n",
      "...          ...         ...         ...         ...          ...   \n",
      "1274  289.539215  360.387726  356.368774  569.646667  1000.063354   \n",
      "1275  256.016449  321.902313  327.064545  518.645142   938.933960   \n",
      "1276  384.673218  449.053314  435.338196  604.533691   969.680542   \n",
      "1277  470.793549  515.778931  499.457947  657.591003   977.025024   \n",
      "1278  437.364288  488.518768  476.529388  622.993958   921.255493   \n",
      "\n",
      "        red_edge3         nir1         nir2        swir2        swir3  \n",
      "0     1481.039185  1616.237793  1665.960938  1502.306396  1020.768982  \n",
      "1     1349.012329  1454.322021  1517.497803  1108.197754   688.409729  \n",
      "2     1336.828125  1424.429321  1518.954346  1012.662659   623.058411  \n",
      "3     1400.040894  1529.145874  1592.148682  1080.450195   642.557251  \n",
      "4     1430.359985  1531.026001  1609.099487  1360.560425   908.636169  \n",
      "...           ...          ...          ...          ...          ...  \n",
      "1274  1045.177002  1154.230835  1204.862549  1019.227966   641.178528  \n",
      "1275   984.077576  1094.847046  1145.825073  1002.388245   620.285767  \n",
      "1276  1017.560852  1125.241211  1167.800415  1138.197266   748.407288  \n",
      "1277  1078.238647  1189.321289  1227.059204  1255.967896   864.312378  \n",
      "1278  1044.851807  1144.544434  1193.209106  1259.196777   849.537354  \n",
      "\n",
      "[1279 rows x 22 columns]\n"
     ]
    }
   ],
   "source": [
    "# Preview data\n",
    "print(masterDF)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Enter one of those values below to index our dictionary and conduct further analsyis on the satellite timeseries for that polygon."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "masterDF.to_csv(f'Fitz_S2_201506_202010_at80_sites_31_45.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## zip everything up prior to download\n",
    "# start up CLI and do an ls command to make sure processing folder exists (in this example it is Fitzgerald)\n",
    "# run: tar -czvf FitzS2.tar.gz Fitzgerald - to zip up work for Sentinel 2 - when unzipping can extract to same folder name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "\n",
    "## Additional information\n",
    "\n",
    "**License:** The code in this notebook is licensed under the [Apache License, Version 2.0](https://www.apache.org/licenses/LICENSE-2.0). \n",
    "Digital Earth Australia data is licensed under the [Creative Commons by Attribution 4.0](https://creativecommons.org/licenses/by/4.0/) license.\n",
    "\n",
    "**Contact:** If you need assistance, please post a question on the [Open Data Cube Slack channel](http://slack.opendatacube.org/) or on the [GIS Stack Exchange](https://gis.stackexchange.com/questions/ask?tags=open-data-cube) using the `open-data-cube` tag (you can view previously asked questions [here](https://gis.stackexchange.com/questions/tagged/open-data-cube)).\n",
    "If you would like to report an issue with this notebook, you can file one on [Github](https://github.com/GeoscienceAustralia/dea-notebooks).\n",
    "\n",
    "**Last modified:** May 2020\n",
    "\n",
    "**Compatible datacube version:** "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.7+142.g7f8581cf\n"
     ]
    }
   ],
   "source": [
    "print(datacube.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tags\n",
    "Browse all available tags on the DEA User Guide's [Tags Index](https://docs.dea.ga.gov.au/genindex.html)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "raw_mimetype": "text/restructuredtext"
   },
   "source": [
    "**Tags**: :index:`NCI compatible`, :index:`sandbox compatible`, :index:`landsat 8`, :index:`dea_plotting`, :index:`dea_datahandling`, :index:`xr_rasterize`, :index:`dea_bandindices`, :index:`dea_spatialtools`, :index:`dea_temporaltools`, :index:`time_buffer`, :index:`load_ard`, :index:`rgb`, :index:`calculate_indices`, :index:`NDVI`, :index:`GeoPandas`, :index:`shapefile`"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "28e0de19801142aa8cfec9c8f07b929d": {
      "model_module": "jupyter-leaflet",
      "model_module_version": "^0.11.1",
      "model_name": "LeafletAttributionControlModel",
      "state": {
       "_model_module_version": "^0.11.1",
       "_view_count": null,
       "_view_module_version": "^0.11.1",
       "options": [
        "position",
        "prefix"
       ],
       "position": "bottomright",
       "prefix": "Leaflet"
      }
     },
     "293470345eef46179b42c21e781119b8": {
      "model_module": "jupyter-leaflet",
      "model_module_version": "^0.11.1",
      "model_name": "LeafletZoomControlModel",
      "state": {
       "_model_module_version": "^0.11.1",
       "_view_count": null,
       "_view_module_version": "^0.11.1",
       "options": [
        "position",
        "zoom_in_text",
        "zoom_in_title",
        "zoom_out_text",
        "zoom_out_title"
       ]
      }
     },
     "2e7ba164aef040a1b2492e8f86a6e4a2": {
      "model_module": "jupyter-leaflet",
      "model_module_version": "^0.11.1",
      "model_name": "LeafletTileLayerModel",
      "state": {
       "_model_module_version": "^0.11.1",
       "_view_count": null,
       "_view_module_version": "^0.11.1",
       "attribution": "Tiles &copy; Esri &mdash; Source: Esri, i-cubed, USDA, USGS, AEX, GeoEye, Getmapping, Aerogrid, IGN, IGP, UPR-EGP, and the GIS User Community",
       "base": true,
       "max_native_zoom": 18,
       "max_zoom": 20,
       "min_native_zoom": 0,
       "min_zoom": 1,
       "name": "Esri.WorldImagery",
       "no_wrap": false,
       "options": [
        "attribution",
        "detect_retina",
        "max_native_zoom",
        "max_zoom",
        "min_native_zoom",
        "min_zoom",
        "no_wrap",
        "tile_size"
       ],
       "url": "http://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}"
      }
     },
     "4566b4dda2f94adeb2ed1242034dfa3b": {
      "model_module": "jupyter-leaflet",
      "model_module_version": "^0.11.1",
      "model_name": "LeafletGeoJSONModel",
      "state": {
       "_model_module_version": "^0.11.1",
       "_view_count": null,
       "_view_module_version": "^0.11.1",
       "data": {
        "bbox": [
         142.4524578701443,
         -32.36320549945,
         142.54736615559136,
         -32.29586369982442
        ],
        "features": [
         {
          "bbox": [
           142.51524944800926,
           -32.31838789697648,
           142.54736615559136,
           -32.29586369982442
          ],
          "geometry": {
           "coordinates": [
            [
             [
              142.51524944800926,
              -32.296091685646715
             ],
             [
              142.546601533663,
              -32.29586369982442
             ],
             [
              142.54736615559136,
              -32.3183698586848
             ],
             [
              142.51526741493365,
              -32.31838789697648
             ],
             [
              142.51524944800926,
              -32.296091685646715
             ]
            ]
           ],
           "type": "Polygon"
          },
          "id": "0",
          "properties": {
           "id": 2,
           "style": {
            "color": "black",
            "fillColor": "#ffffcc",
            "fillOpacity": 0.8,
            "weight": 0.9
           }
          },
          "type": "Feature"
         },
         {
          "bbox": [
           142.4524578701443,
           -32.36320549945,
           142.4845749551165,
           -32.34069269280065
          ],
          "geometry": {
           "coordinates": [
            [
             [
              142.4524578701443,
              -32.340907825281136
             ],
             [
              142.483823262827,
              -32.34069269280065
             ],
             [
              142.4845749551165,
              -32.36320063502121
             ],
             [
              142.45246271443352,
              -32.36320549945
             ],
             [
              142.4524578701443,
              -32.340907825281136
             ]
            ]
           ],
           "type": "Polygon"
          },
          "id": "1",
          "properties": {
           "id": 1,
           "style": {
            "color": "black",
            "fillColor": "#800026",
            "fillOpacity": 0.8,
            "weight": 0.9
           }
          },
          "type": "Feature"
         }
        ],
        "type": "FeatureCollection"
       },
       "style": {
        "fillOpacity": 0.8
       }
      }
     },
     "511e2faf000b4175a340abe63c922c48": {
      "model_module": "jupyter-leaflet",
      "model_module_version": "^0.11.1",
      "model_name": "LeafletMapStyleModel",
      "state": {
       "_model_module_version": "^0.11.1",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "cursor": "move"
      }
     },
     "5343e9e18f24482fa0e779b2c5afb701": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "LabelModel",
      "state": {
       "layout": "IPY_MODEL_bd74b980dd154468a9a7efd47a6623a9",
       "style": "IPY_MODEL_95dc952ff6a6424888378c6ced817e3b"
      }
     },
     "5bd449502886455bb7f0240251445419": {
      "model_module": "jupyter-leaflet",
      "model_module_version": "^0.11.1",
      "model_name": "LeafletMapStyleModel",
      "state": {
       "_model_module_version": "^0.11.1",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "cursor": "grab"
      }
     },
     "7ac22f9ceb6b4937b7bfd6c1f844a8b4": {
      "model_module": "jupyter-leaflet",
      "model_module_version": "^0.11.1",
      "model_name": "LeafletMapModel",
      "state": {
       "_dom_classes": [],
       "_model_module_version": "^0.11.1",
       "_view_count": null,
       "_view_module_version": "^0.11.1",
       "basemap": {
        "attribution": "Tiles &copy; Esri &mdash; Source: Esri, i-cubed, USDA, USGS, AEX, GeoEye, Getmapping, Aerogrid, IGN, IGP, UPR-EGP, and the GIS User Community",
        "max_zoom": 20,
        "name": "Esri.WorldImagery",
        "url": "http://server.arcgisonline.com/ArcGIS/rest/services/World_Imagery/MapServer/tile/{z}/{y}/{x}"
       },
       "center": [
        -32.32953459963721,
        142.4999120128678
       ],
       "controls": [
        "IPY_MODEL_293470345eef46179b42c21e781119b8",
        "IPY_MODEL_28e0de19801142aa8cfec9c8f07b929d"
       ],
       "default_style": "IPY_MODEL_b550d341601f4a349648a5472709282a",
       "dragging_style": "IPY_MODEL_511e2faf000b4175a340abe63c922c48",
       "east": 142.5685501098633,
       "fullscreen": false,
       "interpolation": "bilinear",
       "layers": [
        "IPY_MODEL_2e7ba164aef040a1b2492e8f86a6e4a2",
        "IPY_MODEL_4566b4dda2f94adeb2ed1242034dfa3b"
       ],
       "layout": "IPY_MODEL_94f1d61060f249a9b8e2d1d811cd10b3",
       "modisdate": "yesterday",
       "north": -32.28597166993233,
       "options": [
        "basemap",
        "bounce_at_zoom_limits",
        "box_zoom",
        "center",
        "close_popup_on_click",
        "double_click_zoom",
        "dragging",
        "fullscreen",
        "inertia",
        "inertia_deceleration",
        "inertia_max_speed",
        "interpolation",
        "keyboard",
        "keyboard_pan_offset",
        "keyboard_zoom_offset",
        "max_zoom",
        "min_zoom",
        "scroll_wheel_zoom",
        "tap",
        "tap_tolerance",
        "touch_zoom",
        "world_copy_jump",
        "zoom",
        "zoom_animation_threshold",
        "zoom_start"
       ],
       "south": -32.373002604986546,
       "style": "IPY_MODEL_5bd449502886455bb7f0240251445419",
       "west": 142.4312210083008,
       "zoom": 13
      }
     },
     "94f1d61060f249a9b8e2d1d811cd10b3": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {
       "height": "600px",
       "width": "800px"
      }
     },
     "95dc952ff6a6424888378c6ced817e3b": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "1.5.0",
      "model_name": "DescriptionStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "a1dc5dbe2b344d869bb611b1d486eea1": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "b550d341601f4a349648a5472709282a": {
      "model_module": "jupyter-leaflet",
      "model_module_version": "^0.11.1",
      "model_name": "LeafletMapStyleModel",
      "state": {
       "_model_module_version": "^0.11.1",
       "_view_count": null,
       "_view_module": "@jupyter-widgets/base",
       "_view_module_version": "1.2.0",
       "_view_name": "StyleView",
       "cursor": "grab"
      }
     },
     "bd74b980dd154468a9a7efd47a6623a9": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "1.2.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "e0f2861ca35343b88f5f7eb7bc846394": {
      "model_module": "@jupyter-widgets/output",
      "model_module_version": "1.0.0",
      "model_name": "OutputModel",
      "state": {
       "layout": "IPY_MODEL_a1dc5dbe2b344d869bb611b1d486eea1"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
